{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python on Airflow pipelines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we want to run pipelines many times to collect historical data, we need an scheduling mechanism. This is precisly what Airflow will do for us."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Add Airflow code to the pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will refactor the code of the previous section to run exactly the same pipeline as an Airflow DAG that can be scheduled for a few days to collect historical information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Review the changes in the code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The necessary changes for enabling the python pipeline to run as an Airflow DAG are shown in the next cell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pictures/python_airflow_dag_dev_1.png)\n",
    "![](../pictures/python_airflow_dag_dev_2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the fundamental changes are locatedat the bottom of the file where we write a new header for Airflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Edit the file `pythondag_airflow.py` to include Postgres and Databand security parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All changes for Airflow are already done in [`pythondag_airflow.py`](../dags/pythondag_airflow.py) but we need to enter the Postgres and Databand credentials for your particular environment. Please follow the same instructions as shown in the [previous chapter](./9_python_dag_dev.ipynb) under the paragraph `1.3`. No more changes are necessary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Transfer `pythondag_airflow.py` to Airflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we modified the file, we need to transfer it to Airflow to be registered as a DAG. We begin with the usual login to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Replace the command with your own one inside the single quotes and run the cell\n",
    "# Example OC_LOGIN_COMMAND='oc login --token=sha256~3bR5KXgwiUoaQiph2_kIXCDQnVfm_HQy3YwU2m-UOrs --server=https://c109-e.us-east.containers.cloud.ibm.com:31656'\n",
    "OC_LOGIN_COMMAND='oc login --token=sha256~6Xs6va20JZ2CFhS61HN6bpQC2z075XZbhIJt3tZ8L6w --server=https://c109-e.us-east.containers.cloud.ibm.com:31470'\n",
    "$OC_LOGIN_COMMAND\n",
    "oc project airflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to verify that the file `pythondag_airflow.py` is located in the DAGs directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# you may need to modify the cd command to place yourself in the DAGs directory\n",
    "pwd\n",
    "cd ../dags\n",
    "ls -l\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for a `pythondag_airflow.py` like this:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/Users/Angel/MyIBM/git/databand-workshop/jupyter\n",
    "total 64\n",
    "-rw-r--r--  1 Angel  wheel   152 Mar 13 11:06 databand_airflow_monitor.py\n",
    "-rw-r--r--  1 Angel  wheel  2128 Mar 20 13:17 motogp_dag.py\n",
    "-rw-r--r--  1 Angel  wheel  4917 Mar 21 09:03 pythondag.py\n",
    "-rw-r--r--  1 Angel  wheel  4689 Mar 21 16:51 pythondag_airflow.py\n",
    "drwxr-xr-x  8 Angel  wheel   256 Mar 13 11:06 sql\n",
    "-rw-r--r--  1 Angel  wheel  3372 Mar 20 15:09 sql_airflow_dag.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can run this cell to transfer the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to copy the file to the openshift cluster\n",
    "oc cp pythondag_airflow.py airflow-worker-0:dags/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Enable the run on Airflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the file is transfered to Airflow you may need to wait about 5 minutes until the the DAG is visible. Then, you need to activate it:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pictures/python_airflow_enable_DAG.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the DAG is activated and will run every 17 minutes. Leave it running for a few days if you whish to see historical data or go to the next section where we see how it will look like."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Display performance data with Databand"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new created pipeline can will be shown as `Python_Airflow_DAG` as it is hardcoded in the header section of the python code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pictures/python_airflow_dag_history_1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline ran 240 times so far and the historical data can be shown like follows:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pictures/python_airflow_dag_history_2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, when things run well, all graphics and trends look like very boring. In our case the number of rows written and read is the same during the whole history.\n",
    "\n",
    "However, there are ways to see more exciting curves. Just proceed as instructed in the following picture:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pictures/python_airflow_dag_history_3.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, there are variations in the elapsed runtime caused by the concurrency of several jobs while the performance data was collected. You can now switch to the Datasets view and see the cumulated traffic of records in the last days:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pictures/python_airflow_dag_history_4.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "Next Section: [DataStage pipelines ](./11_datastage_dev.ipynb)    \n",
    "Previous Section: [Python pipelines](./9_python_dag_dev.ipynb)   \n",
    "\n",
    "[Return to main](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
