{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Airflow pipelines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by describing a simple DAG that will perform a series of simple steps in a Postgres table (create the table, load some data, count them and, finally, drop or delete the table randomly). The implementation of all DAGs are placed on the `dags` directory of the git repository and, in this particular case, the sql comands and even the csv data will be placed in a separate `sql` subdirectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 Angel  wheel  3372 Mar 20 15:09 sql_airflow_dag.py\n",
      "\n",
      "sql:\n",
      "total 312\n",
      "-rw-r--r--@ 1 Angel  wheel  137845 Mar 13 11:06 motogp.csv\n",
      "-rw-r--r--@ 1 Angel  wheel     181 Mar 13 11:06 motogp_create_table.sql\n",
      "-rw-r--r--  1 Angel  wheel      21 Mar 13 11:06 motogp_delete_table.sql\n",
      "-rw-r--r--  1 Angel  wheel      20 Mar 13 11:06 motogp_drop_table.sql\n",
      "-rw-r--r--  1 Angel  wheel     469 Mar 13 11:06 motogp_load_table.py\n",
      "-rw-r--r--@ 1 Angel  wheel      30 Mar 13 11:06 motogp_select_table.sql\n"
     ]
    }
   ],
   "source": [
    "# You may need to change the cd command in order to be in the right directory\n",
    "# Execute this cell\n",
    "\n",
    "cd ../dags/\n",
    "ls -l sql*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything went well, you will see an output similar to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Do not execute this cell. Just for information\n",
    "-rw-r--r--  1 Angel  wheel  3372 Mar 20 15:09 sql_airflow_dag.py\n",
    "\n",
    "sql:\n",
    "total 312\n",
    "-rw-r--r--@ 1 Angel  wheel  137845 Mar 13 11:06 motogp.csv\n",
    "-rw-r--r--@ 1 Angel  wheel     181 Mar 13 11:06 motogp_create_table.sql\n",
    "-rw-r--r--  1 Angel  wheel      21 Mar 13 11:06 motogp_delete_table.sql\n",
    "-rw-r--r--  1 Angel  wheel      20 Mar 13 11:06 motogp_drop_table.sql\n",
    "-rw-r--r--  1 Angel  wheel     469 Mar 13 11:06 motogp_load_table.py\n",
    "-rw-r--r--@ 1 Angel  wheel      30 Mar 13 11:06 motogp_select_table.sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More interesting than the contents of the `*.sql` files (which are simple sql statements) is the file [sql_airflow_dag.py](../dags/sql_airflow_dag.py). Even if you are not a python programmer or have no Airflow skills, it is advisable to review the stucture of the code to understand what and how the DAG will do:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pictures/sql_code_comment.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we copied this file to the Airflow containers in the previous section of this workshop, the DAG will be visible on the Airflow console."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pictures/sql_dag_identification_on_airflow.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions of the picture above to run the DAG and click on the name of the DAG to see a graphical representation (note that the `graph` tab is highlighted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pictures/sql_dag_airflow_overview.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open the Databand main interface and navigate to the Pipelines menu on the left, you will see a list of all the pipelines, including the one we are focusing now, labeled as `SQL_Airflow_DAG`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pictures/sql_pipeline_identification_on_databand.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you click on the name of the pipeline, all the executions of this pipeline will be listed:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pictures/sql_run_databand.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the deatils of each run, click on anyone of them:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pictures/sql_dag_databand_overview.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to remark that this DAG has no sign of Databand at all, i.e. we didn't write special line in the code and nothing implies that it will be monitored by Databand. Actually, it will be scheduled and run by Airflow, which will capture the execution data as any other DAG. The execution data will be pulled by Databand to display it as a pipeline. \n",
    "\n",
    "The information collected by Databand will include the elapsed runtimes of each task and its return codes. This is a basic start that will be enhanced in the next chapters where we will see more valuable information.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "Next Section: [Python pipelines](./9_python_dag_dev.ipynb)\n",
    "\n",
    "Previous Section: [Preparation](./7_dags_dev.ipynb)   \n",
    "\n",
    "[Return to main](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
